#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šæµ·é¤å…å¯†åº¦åˆ†æç¨‹åº
åŠŸèƒ½ï¼šè®¡ç®—é¤å…å‘¨å›´æŒ‡å®šåŠå¾„å†…çš„é¤å…æ€»æ•°å’ŒåŒç±»å‹é¤å…æ•°é‡ï¼Œåˆ†æç«äº‰ç¯å¢ƒ

ä½¿ç”¨æ–¹æ³•:
    python è¯¾é¢˜3_optimized.py
"""

import pandas as pd
import numpy as np
from math import radians, sin, cos, sqrt, atan2
from sklearn.neighbors import BallTree
import time
import logging
import warnings
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
from dataclasses import dataclass
import os

warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/restaurant_density_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class Config:
    """é…ç½®ç±»"""
    # æ–‡ä»¶è·¯å¾„é…ç½®
    INPUT_FILE: str = 'data/è¯¾é¢˜æ•°æ®_ç­›é€‰å.csv'
    OUTPUT_FILE: str = 'data/restaurants_with_density.csv'
    OUTPUT_DIR: str = 'data/density_analysis_outputs'
    
    # åˆ†æå‚æ•°
    SEARCH_RADIUS: float = 2000.0  # æœç´¢åŠå¾„ï¼ˆç±³ï¼‰
    BATCH_SIZE: int = 500  # æ‰¹å¤„ç†å¤§å°
    PROGRESS_INTERVAL: int = 100  # è¿›åº¦æ˜¾ç¤ºé—´éš”
    
    # æ€§èƒ½é…ç½®
    USE_VECTORIZATION: bool = True  # æ˜¯å¦ä½¿ç”¨å‘é‡åŒ–è®¡ç®—
    EARTH_RADIUS: float = 6371000.0  # åœ°çƒåŠå¾„ï¼ˆç±³ï¼‰

class SpatialCalculator:
    """ç©ºé—´è®¡ç®—å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        logger.info("ç©ºé—´è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def haversine_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """
        ä½¿ç”¨Haversineå…¬å¼è®¡ç®—ä¸¤ä¸ªç»çº¬åº¦åæ ‡ä¹‹é—´çš„çƒé¢è·ç¦»
        
        Args:
            lat1, lon1: ç¬¬ä¸€ä¸ªç‚¹çš„çº¬åº¦å’Œç»åº¦
            lat2, lon2: ç¬¬äºŒä¸ªç‚¹çš„çº¬åº¦å’Œç»åº¦
            
        Returns:
            float: ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»ï¼ˆç±³ï¼‰
        """
        try:
            # å°†åè¿›åˆ¶åº¦æ•°è½¬æ¢ä¸ºå¼§åº¦
            lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
            
            # Haversineå…¬å¼
            dlon = lon2 - lon1
            dlat = lat2 - lat1
            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
            c = 2 * atan2(sqrt(a), sqrt(1-a))
            return c * self.config.EARTH_RADIUS
        except Exception as e:
            logger.error(f"è·ç¦»è®¡ç®—å¤±è´¥: {e}")
            return float('inf')
    
    def haversine_distance_vectorized(self, coords1: np.ndarray, coords2: np.ndarray) -> np.ndarray:
        """
        å‘é‡åŒ–è®¡ç®—Haversineè·ç¦»
        
        Args:
            coords1: ç¬¬ä¸€ç»„åæ ‡ (N, 2) - [lat, lon]
            coords2: ç¬¬äºŒç»„åæ ‡ (M, 2) - [lat, lon]
            
        Returns:
            np.ndarray: è·ç¦»çŸ©é˜µ (N, M)
        """
        try:
            # è½¬æ¢ä¸ºå¼§åº¦
            coords1_rad = np.deg2rad(coords1)
            coords2_rad = np.deg2rad(coords2)
            
            # æå–ç»çº¬åº¦
            lat1 = coords1_rad[:, 0:1]
            lon1 = coords1_rad[:, 1:2]
            lat2 = coords2_rad[:, 0:1]
            lon2 = coords2_rad[:, 1:2]
            
            # è®¡ç®—å·®å€¼
            dlat = lat2.T - lat1
            dlon = lon2.T - lon1
            
            # Haversineå…¬å¼
            a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2.T) * np.sin(dlon/2)**2
            c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
            
            return c * self.config.EARTH_RADIUS
            
        except Exception as e:
            logger.error(f"å‘é‡åŒ–è·ç¦»è®¡ç®—å¤±è´¥: {e}")
            return np.full((coords1.shape[0], coords2.shape[0]), float('inf'))

class DensityAnalyzer:
    """å¯†åº¦åˆ†æå™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.spatial_calculator = SpatialCalculator(config)
        logger.info("å¯†åº¦åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate_restaurant_density_balltree(self, restaurants_df: pd.DataFrame) -> pd.DataFrame:
        """
        ä½¿ç”¨BallTreeè®¡ç®—é¤å…å¯†åº¦ï¼ˆæ¨èæ–¹æ³•ï¼‰
        
        Args:
            restaurants_df: é¤å…æ•°æ®DataFrame
            
        Returns:
            DataFrame: æ·»åŠ äº†å¯†åº¦ä¿¡æ¯çš„é¤å…æ•°æ®
        """
        logger.info(f"å¼€å§‹ä½¿ç”¨BallTreeè®¡ç®— {len(restaurants_df)} å®¶é¤å…çš„å¯†åº¦...")
        start_time = time.time()
        
        # åˆ›å»ºç»“æœDataFrameçš„å‰¯æœ¬
        result_df = restaurants_df.copy()
        result_df['total_nearby'] = 0
        result_df['same_type_nearby'] = 0
        
        # åˆ›å»ºé¤å…ä½ç½®çš„çƒé¢åæ ‡æ•°ç»„ï¼ˆè½¬æ¢ä¸ºå¼§åº¦ï¼‰
        coords = np.deg2rad(restaurants_df[['latitude', 'longitude']].values)
        
        # åˆ›å»ºBallTreeè¿›è¡Œé«˜æ•ˆçš„ç©ºé—´æŸ¥è¯¢
        tree = BallTree(coords, metric='haversine')
        
        # æŸ¥è¯¢åŠå¾„ï¼ˆè½¬æ¢ä¸ºå¼§åº¦ï¼Œé™¤ä»¥åœ°çƒåŠå¾„ï¼‰
        radius_rad = self.config.SEARCH_RADIUS / self.config.EARTH_RADIUS
        
        # æ‰¹é‡æŸ¥è¯¢ä»¥æé«˜æ€§èƒ½
        all_indices = tree.query_radius(coords, r=radius_rad)
        
        # å¤„ç†æŸ¥è¯¢ç»“æœ
        for idx, indices in enumerate(all_indices):
            # æ’é™¤è‡ªèº«
            indices = [i for i in indices if i != idx]
            
            # è®¡ç®—å‘¨å›´é¤å…æ€»æ•°
            total_count = len(indices)
            result_df.at[idx, 'total_nearby'] = total_count
            
            # è®¡ç®—åŒç±»å‹é¤å…æ•°é‡
            if total_count > 0:
                current_type = restaurants_df.iloc[idx]['ç±»å‹']
                same_type_count = sum(1 for i in indices if restaurants_df.iloc[i]['ç±»å‹'] == current_type)
                result_df.at[idx, 'same_type_nearby'] = same_type_count
            
            # æ˜¾ç¤ºè¿›åº¦
            if (idx + 1) % self.config.PROGRESS_INTERVAL == 0:
                logger.info(f"å·²å¤„ç† {idx + 1}/{len(restaurants_df)} å®¶é¤å…")
        
        elapsed_time = time.time() - start_time
        logger.info(f"BallTreeå¯†åº¦è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
        return result_df
    
    def calculate_restaurant_density_vectorized(self, restaurants_df: pd.DataFrame) -> pd.DataFrame:
        """
        ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•è®¡ç®—é¤å…å¯†åº¦ï¼ˆé€‚ç”¨äºå°æ•°æ®é›†ï¼‰
        
        Args:
            restaurants_df: é¤å…æ•°æ®DataFrame
            
        Returns:
            DataFrame: æ·»åŠ äº†å¯†åº¦ä¿¡æ¯çš„é¤å…æ•°æ®
        """
        logger.info(f"å¼€å§‹ä½¿ç”¨å‘é‡åŒ–æ–¹æ³•è®¡ç®— {len(restaurants_df)} å®¶é¤å…çš„å¯†åº¦...")
        start_time = time.time()
        
        # åˆ›å»ºç»“æœDataFrameçš„å‰¯æœ¬
        result_df = restaurants_df.copy()
        result_df['total_nearby'] = 0
        result_df['same_type_nearby'] = 0
        
        # è·å–åæ ‡
        coords = restaurants_df[['latitude', 'longitude']].values
        
        # åˆ†æ‰¹å¤„ç†ä»¥æé«˜å†…å­˜æ•ˆç‡
        batch_size = self.config.BATCH_SIZE
        total_batches = (len(restaurants_df) + batch_size - 1) // batch_size
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(restaurants_df))
            batch_coords = coords[start_idx:end_idx]
            
            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ({start_idx}-{end_idx})")
            
            # è®¡ç®—å½“å‰æ‰¹æ¬¡åˆ°æ‰€æœ‰é¤å…çš„è·ç¦»
            distances = self.spatial_calculator.haversine_distance_vectorized(batch_coords, coords)
            
            # ç»Ÿè®¡æ¯ä¸ªé¤å…å‘¨å›´çš„é¤å…æ•°é‡
            for i, (batch_i, global_i) in enumerate(range(start_idx, end_idx)):
                # æ‰¾åˆ°æŒ‡å®šåŠå¾„å†…çš„é¤å…
                nearby_mask = distances[i] <= self.config.SEARCH_RADIUS
                nearby_indices = np.where(nearby_mask)[0]
                
                # æ’é™¤è‡ªèº«
                nearby_indices = nearby_indices[nearby_indices != global_i]
                
                # è®¡ç®—å‘¨å›´é¤å…æ€»æ•°
                total_count = len(nearby_indices)
                result_df.at[global_i, 'total_nearby'] = total_count
                
                # è®¡ç®—åŒç±»å‹é¤å…æ•°é‡
                if total_count > 0:
                    current_type = restaurants_df.iloc[global_i]['ç±»å‹']
                    same_type_mask = restaurants_df.iloc[nearby_indices]['ç±»å‹'] == current_type
                    same_type_count = np.sum(same_type_mask)
                    result_df.at[global_i, 'same_type_nearby'] = same_type_count
        
        elapsed_time = time.time() - start_time
        logger.info(f"å‘é‡åŒ–å¯†åº¦è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
        
        return result_df
    
    def calculate_restaurant_density(self, restaurants_df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—é¤å…å¯†åº¦ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ–¹æ³•ï¼‰
        
        Args:
            restaurants_df: é¤å…æ•°æ®DataFrame
            
        Returns:
            DataFrame: æ·»åŠ äº†å¯†åº¦ä¿¡æ¯çš„é¤å…æ•°æ®
        """
        # æ ¹æ®æ•°æ®é‡è‡ªåŠ¨é€‰æ‹©è®¡ç®—æ–¹æ³•
        if len(restaurants_df) > 1000 and self.config.USE_VECTORIZATION:
            logger.info("æ•°æ®é‡è¾ƒå¤§ï¼Œä½¿ç”¨BallTreeæ–¹æ³•")
            return self.calculate_restaurant_density_balltree(restaurants_df)
        else:
            logger.info("æ•°æ®é‡è¾ƒå°ï¼Œä½¿ç”¨å‘é‡åŒ–æ–¹æ³•")
            return self.calculate_restaurant_density_vectorized(restaurants_df)

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self._setup_output_dir()
        logger.info("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_output_dir(self):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        Path(self.config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
        Path('logs').mkdir(exist_ok=True)
    
    def load_and_validate_data(self) -> pd.DataFrame:
        """åŠ è½½å’ŒéªŒè¯æ•°æ®"""
        try:
            if not Path(self.config.INPUT_FILE).exists():
                raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {self.config.INPUT_FILE}")
            
            df = pd.read_csv(self.config.INPUT_FILE)
            logger.info(f"æˆåŠŸåŠ è½½æ•°æ®: {df.shape}")
            
            # éªŒè¯å¿…è¦çš„åˆ—
            required_columns = ['å•†é“º', 'latitude', 'longitude', 'ç±»å‹']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            
            # å¤„ç†ç¼ºå¤±å€¼
            original_count = len(df)
            df = df.dropna(subset=['latitude', 'longitude', 'ç±»å‹'])
            cleaned_count = len(df)
            
            if cleaned_count < original_count:
                logger.warning(f"æ¸…ç†ç¼ºå¤±å€¼åï¼Œæ•°æ®ä» {original_count} æ¡å‡å°‘åˆ° {cleaned_count} æ¡")
            
            logger.info(f"æ•°æ®éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®: {cleaned_count} æ¡")
            return df
            
        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def save_results(self, df: pd.DataFrame) -> None:
        """ä¿å­˜ç»“æœ"""
        try:
            # ä¿å­˜ä¸»è¦ç»“æœ
            df.to_csv(self.config.OUTPUT_FILE, index=False, encoding='utf-8')
            logger.info(f"ä¸»è¦ç»“æœå·²ä¿å­˜åˆ°: {self.config.OUTPUT_FILE}")
            
            # ä¿å­˜å¯†åº¦ç»Ÿè®¡æŠ¥å‘Š
            self._save_density_report(df)
            
        except Exception as e:
            logger.error(f"ç»“æœä¿å­˜å¤±è´¥: {e}")
            raise
    
    def _save_density_report(self, df: pd.DataFrame) -> None:
        """ä¿å­˜å¯†åº¦åˆ†ææŠ¥å‘Š"""
        report_file = Path(self.config.OUTPUT_DIR) / 'density_analysis_report.txt'
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("ä¸Šæµ·é¤å…å¯†åº¦åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"åˆ†æå‚æ•°:\n")
                f.write(f"æœç´¢åŠå¾„: {self.config.SEARCH_RADIUS} ç±³\n")
                f.write(f"æ€»é¤å…æ•°é‡: {len(df)}\n\n")
                
                f.write(f"å¯†åº¦ç»Ÿè®¡:\n")
                f.write(f"å¹³å‡æ¯å®¶é¤å…å‘¨å›´é¤å…æ€»æ•°: {df['total_nearby'].mean():.2f}\n")
                f.write(f"ä¸­ä½æ•°: {df['total_nearby'].median():.2f}\n")
                f.write(f"æ ‡å‡†å·®: {df['total_nearby'].std():.2f}\n")
                f.write(f"æœ€å°å€¼: {df['total_nearby'].min()}\n")
                f.write(f"æœ€å¤§å€¼: {df['total_nearby'].max()}\n\n")
                
                f.write(f"åŒç±»å‹ç«äº‰ç»Ÿè®¡:\n")
                f.write(f"å¹³å‡æ¯å®¶é¤å…å‘¨å›´åŒç±»å‹é¤å…æ•°: {df['same_type_nearby'].mean():.2f}\n")
                f.write(f"ä¸­ä½æ•°: {df['same_type_nearby'].median():.2f}\n")
                f.write(f"æ ‡å‡†å·®: {df['same_type_nearby'].std():.2f}\n")
                f.write(f"æœ€å°å€¼: {df['same_type_nearby'].min()}\n")
                f.write(f"æœ€å¤§å€¼: {df['same_type_nearby'].max()}\n\n")
                
                # ç«äº‰æœ€æ¿€çƒˆçš„åŒºåŸŸ
                max_total_idx = df['total_nearby'].idxmax()
                max_total_restaurant = df.loc[max_total_idx]
                f.write(f"ç«äº‰æœ€æ¿€çƒˆçš„åŒºåŸŸ:\n")
                f.write(f"é¤å…åç§°: {max_total_restaurant['å•†é“º']}\n")
                f.write(f"é¤å…ç±»å‹: {max_total_restaurant['ç±»å‹']}\n")
                f.write(f"å‘¨å›´é¤å…æ€»æ•°: {max_total_restaurant['total_nearby']}\n")
                f.write(f"åŒç±»å‹é¤å…æ•°é‡: {max_total_restaurant['same_type_nearby']}\n")
                f.write(f"åæ ‡: ({max_total_restaurant['latitude']:.6f}, {max_total_restaurant['longitude']:.6f})\n\n")
                
                # åŒç±»å‹ç«äº‰æœ€æ¿€çƒˆçš„é¤å…
                max_same_type_idx = df['same_type_nearby'].idxmax()
                max_same_type_restaurant = df.loc[max_same_type_idx]
                f.write(f"åŒç±»å‹ç«äº‰æœ€æ¿€çƒˆçš„é¤å…:\n")
                f.write(f"é¤å…åç§°: {max_same_type_restaurant['å•†é“º']}\n")
                f.write(f"é¤å…ç±»å‹: {max_same_type_restaurant['ç±»å‹']}\n")
                f.write(f"å‘¨å›´åŒç±»å‹é¤å…æ•°é‡: {max_same_type_restaurant['same_type_nearby']}\n")
                f.write(f"å‘¨å›´é¤å…æ€»æ•°: {max_same_type_restaurant['total_nearby']}\n")
                f.write(f"åæ ‡: ({max_same_type_restaurant['latitude']:.6f}, {max_same_type_restaurant['longitude']:.6f})\n\n")
                
                # æŒ‰ç±»å‹ç»Ÿè®¡ç«äº‰æƒ…å†µ
                f.write(f"å„ç±»å‹é¤å…çš„ç«äº‰æƒ…å†µ:\n")
                type_stats = df.groupby('ç±»å‹').agg({
                    'total_nearby': ['mean', 'median', 'std'],
                    'same_type_nearby': ['mean', 'median', 'std']
                }).round(2)
                f.write(f"{type_stats.to_string()}\n")
            
            logger.info(f"å¯†åº¦åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

class ResultAnalyzer:
    """ç»“æœåˆ†æå™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        logger.info("ç»“æœåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_results(self, df: pd.DataFrame) -> None:
        """åˆ†æç»“æœå¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        logger.info("å¼€å§‹åˆ†æç»“æœ...")
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\nå¯†åº¦åˆ†æç»“æœç»Ÿè®¡:")
        logger.info(f"æœç´¢åŠå¾„: {self.config.SEARCH_RADIUS} ç±³")
        logger.info(f"æ€»é¤å…æ•°é‡: {len(df)}")
        logger.info(f"å¹³å‡æ¯å®¶é¤å…å‘¨å›´é¤å…æ€»æ•°: {df['total_nearby'].mean():.2f}")
        logger.info(f"å¹³å‡æ¯å®¶é¤å…å‘¨å›´åŒç±»å‹é¤å…æ•°é‡: {df['same_type_nearby'].mean():.2f}")
        
        # ç«äº‰æœ€æ¿€çƒˆçš„åŒºåŸŸ
        max_total_idx = df['total_nearby'].idxmax()
        max_total_restaurant = df.loc[max_total_idx]
        logger.info(f"\nğŸ† ç«äº‰æœ€æ¿€çƒˆçš„åŒºåŸŸ:")
        logger.info(f"  é¤å…åç§°: {max_total_restaurant['å•†é“º']}")
        logger.info(f"  é¤å…ç±»å‹: {max_total_restaurant['ç±»å‹']}")
        logger.info(f"  å‘¨å›´é¤å…æ€»æ•°: {max_total_restaurant['total_nearby']}")
        logger.info(f"  åŒç±»å‹é¤å…æ•°é‡: {max_total_restaurant['same_type_nearby']}")
        
        # åŒç±»å‹ç«äº‰æœ€æ¿€çƒˆçš„é¤å…
        max_same_type_idx = df['same_type_nearby'].idxmax()
        max_same_type_restaurant = df.loc[max_same_type_idx]
        logger.info(f"\nğŸ”¥ åŒç±»å‹ç«äº‰æœ€æ¿€çƒˆçš„é¤å…:")
        logger.info(f"  é¤å…åç§°: {max_same_type_restaurant['å•†é“º']}")
        logger.info(f"  é¤å…ç±»å‹: {max_same_type_restaurant['ç±»å‹']}")
        logger.info(f"  å‘¨å›´åŒç±»å‹é¤å…æ•°é‡: {max_same_type_restaurant['same_type_nearby']}")
        logger.info(f"  å‘¨å›´é¤å…æ€»æ•°: {max_same_type_restaurant['total_nearby']}")
        
        # ç«äº‰ç¯å¢ƒåˆ†å¸ƒ
        logger.info(f"\nğŸ“Š ç«äº‰ç¯å¢ƒåˆ†å¸ƒ:")
        total_nearby_ranges = [
            (0, 10, "ä½ç«äº‰"),
            (11, 30, "ä¸­ç­‰ç«äº‰"),
            (31, 60, "é«˜ç«äº‰"),
            (61, float('inf'), "æé«˜ç«äº‰")
        ]
        
        for min_val, max_val, label in total_nearby_ranges:
            if max_val == float('inf'):
                count = len(df[df['total_nearby'] >= min_val])
            else:
                count = len(df[(df['total_nearby'] >= min_val) & (df['total_nearby'] <= max_val)])
            percentage = (count / len(df)) * 100
            logger.info(f"  {label}: {count}å®¶é¤å… ({percentage:.1f}%)")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=== ä¸Šæµ·é¤å…å¯†åº¦åˆ†æç¨‹åºå¯åŠ¨ ===")
    
    try:
        # 1. åˆå§‹åŒ–é…ç½®
        config = Config()
        
        # 2. åŠ è½½å’ŒéªŒè¯æ•°æ®
        processor = DataProcessor(config)
        restaurants_df = processor.load_and_validate_data()
        
        # 3. è®¡ç®—é¤å…å¯†åº¦
        analyzer = DensityAnalyzer(config)
        start_time = time.time()
        
        restaurants_with_density = analyzer.calculate_restaurant_density(restaurants_df)
        
        total_time = time.time() - start_time
        logger.info(f"å¯†åº¦è®¡ç®—å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # 4. ä¿å­˜ç»“æœ
        processor.save_results(restaurants_with_density)
        
        # 5. åˆ†æç»“æœ
        result_analyzer = ResultAnalyzer(config)
        result_analyzer.analyze_results(restaurants_with_density)
        
        logger.info("ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ä¸»è¦ç»“æœä¿å­˜åœ¨: {config.OUTPUT_FILE}")
        logger.info(f"è¯¦ç»†æŠ¥å‘Šä¿å­˜åœ¨: {config.OUTPUT_DIR}")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()
